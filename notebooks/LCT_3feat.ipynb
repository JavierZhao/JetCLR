{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5be21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:28.803698Z",
     "start_time": "2024-01-22T19:44:28.557014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssl-jet-vol-v2/JetCLR/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863be33e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:32.030807Z",
     "start_time": "2024-01-22T19:44:28.806903Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import argparse\n",
    "sys.path.append('../')\n",
    "\n",
    "# load torch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load custom modules required for jetCLR training\n",
    "from scripts.modules.jet_augs import rotate_jets, distort_jets, rescale_pts, crop_jets, translate_jets, collinear_fill_jets\n",
    "from scripts.modules.transformer import Transformer\n",
    "from scripts.modules.losses import contrastive_loss, align_loss, uniform_loss\n",
    "from scripts.modules.perf_eval import get_perf_stats, linear_classifier_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c9bcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:32.041127Z",
     "start_time": "2024-01-22T19:44:32.033403Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(dataset_path, flag, n_files=-1):\n",
    "    if args.full_kinematics:\n",
    "        data_files = glob.glob(f\"{dataset_path}/{flag}/processed/7_features_raw/data/*\")\n",
    "    else:\n",
    "        data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features/data/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        if args.full_kinematics:\n",
    "            data.append(np.load(f\"{dataset_path}/{flag}/processed/7_features_raw/data/data_{i}.npy\")) \n",
    "        else:\n",
    "            data.append(torch.load(f\"{dataset_path}/{flag}/processed/3_features/data/data_{i}.pt\")) \n",
    "        print(f\"--- loaded file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_labels(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features/labels/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data.append(torch.load(f\"{dataset_path}/{flag}/processed/3_features/labels/labels_{i}.pt\"))\n",
    "        print(f\"--- loaded label file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35304f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:32.063618Z",
     "start_time": "2024-01-22T19:44:32.043405Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971b285d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:32.072733Z",
     "start_time": "2024-01-22T19:44:32.067310Z"
    }
   },
   "outputs": [],
   "source": [
    "args.sbratio = 1\n",
    "args.output_dim = 1000\n",
    "args.model_dim = 1000 \n",
    "args.n_heads = 4\n",
    "args.dim_feedforward= 1000\n",
    "args.n_layers= 4 \n",
    "args.learning_rate = 0.00005 \n",
    "args.n_head_layers = 2 \n",
    "args.opt = \"adam\"\n",
    "args.label = \"zz-simCLR-trial\"\n",
    "args.load_path = f\"/ssl-jet-vol-v2/JetCLR/models/experiments/{args.label}/final_model.pt\"\n",
    "args.trs = True\n",
    "args.mask = False\n",
    "args.cmask = True\n",
    "args.batch_size = 128\n",
    "args.trsw = 0.1\n",
    "args.full_kinematics = False\n",
    "args.num_files = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a56cc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:33.659854Z",
     "start_time": "2024-01-22T19:44:32.074892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "--- loaded file 0 from `train` directory\n",
      "--- loaded label file 0 from `train` directory\n",
      "input_dim:  3\n",
      "shuffling data and doing the S/B split\n"
     ]
    }
   ],
   "source": [
    "print( \"loading data\")\n",
    "data = load_data(\"/ssl-jet-vol-v2/toptagging\", \"train\", args.num_files)\n",
    "labels = load_labels(\"/ssl-jet-vol-v2/toptagging\", \"train\", args.num_files)\n",
    "tr_dat_in = torch.concatenate(data, axis=0).numpy()  # Concatenate along the first axis\n",
    "tr_lab_in = torch.concatenate(labels, axis=0).numpy()\n",
    "# tr_dat_in = tr_dat_in[:10000]\n",
    "# tr_lab_in = tr_lab_in[:10000]\n",
    "\n",
    "# input dim to the transformer -> (pt,eta,phi)\n",
    "input_dim = tr_dat_in.shape[1]\n",
    "print(\"input_dim: \", input_dim)\n",
    "\n",
    "# creating the training dataset\n",
    "print( \"shuffling data and doing the S/B split\", flush=True )\n",
    "tr_bkg_dat = tr_dat_in[ tr_lab_in==0 ].copy()\n",
    "tr_sig_dat = tr_dat_in[ tr_lab_in==1 ].copy()\n",
    "nbkg_tr = int( tr_bkg_dat.shape[0] )\n",
    "nsig_tr = int( args.sbratio * nbkg_tr )\n",
    "list_tr_dat = list( tr_bkg_dat[ 0:nbkg_tr ] ) + list( tr_sig_dat[ 0:nsig_tr ] )\n",
    "list_tr_lab = [ 0 for i in range( nbkg_tr ) ] + [ 1 for i in range( nsig_tr ) ]\n",
    "ldz_tr = list( zip( list_tr_dat, list_tr_lab ) )\n",
    "random.shuffle( ldz_tr )\n",
    "tr_dat, tr_lab = zip( *ldz_tr )\n",
    "# reducing the training data\n",
    "tr_dat = np.array( tr_dat )\n",
    "tr_lab = np.array( tr_lab )\n",
    "\n",
    "# create two validation sets: \n",
    "# one for training the linear classifier test (LCT)\n",
    "# and one for testing on it\n",
    "# we will do this just with tr_dat_in, but shuffled and split 50/50\n",
    "# this should be fine because the jetCLR training doesn't use labels\n",
    "# we want the LCT to use S/B=1 all the time\n",
    "list_vl_dat = list( tr_dat_in.copy() )\n",
    "list_vl_lab = list( tr_lab_in.copy() )\n",
    "ldz_vl = list( zip( list_vl_dat, list_vl_lab ) )\n",
    "random.shuffle( ldz_vl )\n",
    "vl_dat, vl_lab = zip( *ldz_vl )\n",
    "vl_dat = np.array( vl_dat )\n",
    "vl_lab = np.array( vl_lab )\n",
    "vl_len = vl_dat.shape[0]\n",
    "vl_split_len = int( vl_len/2 )\n",
    "vl_dat_1 = vl_dat[ 0:vl_split_len ]\n",
    "vl_lab_1 = vl_lab[ 0:vl_split_len ]\n",
    "vl_dat_2 = vl_dat[ -vl_split_len: ]\n",
    "vl_lab_2 = vl_lab[ -vl_split_len: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39398fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:44:38.185601Z",
     "start_time": "2024-01-22T19:44:33.661953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising the network\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set-up parameters for the LCT\n",
    "linear_input_size = args.output_dim\n",
    "linear_n_epochs = 750\n",
    "linear_learning_rate = 0.001\n",
    "linear_batch_size = 128\n",
    "\n",
    "# initialise the network\n",
    "print( \"initialising the network\", flush=True )\n",
    "net = Transformer( input_dim, args.model_dim, args.output_dim, args.n_heads, args.dim_feedforward, args.n_layers, args.learning_rate, args.n_head_layers, dropout=0.1, opt=args.opt )\n",
    "# send network to device\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "net.to( device )\n",
    "# print(net)\n",
    "net.load_state_dict(torch.load(f\"{args.load_path}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6cb977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:45:56.881345Z",
     "start_time": "2024-01-22T19:44:38.187823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the final LCT run\n",
      "obtaining representations\n"
     ]
    }
   ],
   "source": [
    "print( \"starting the final LCT run\", flush=True )\n",
    "print(\"obtaining representations\")\n",
    "# evaluate the network on the testing data, applying some augmentations first if it's required\n",
    "# if args.trs:\n",
    "#     vl_dat_1 = translate_jets( vl_dat_1, width=args.trsw )\n",
    "#     vl_dat_2 = translate_jets( vl_dat_2, width=args.trsw )\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    #vl_reps_1 = F.normalize( net.forward_batchwise( torch.Tensor( vl_dat_1 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu(), dim=-1 ).numpy()\n",
    "    #vl_reps_2 = F.normalize( net.forward_batchwise( torch.Tensor( vl_dat_2 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu(), dim=-1 ).numpy()\n",
    "    vl_reps_1 = net.forward_batchwise( torch.Tensor( vl_dat_1 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu().numpy()\n",
    "    vl_reps_2 = net.forward_batchwise( torch.Tensor( vl_dat_2 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu().numpy()\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c67870df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:54:35.813109Z",
     "start_time": "2024-01-22T19:45:56.883902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished obtaining representations, starting LCT\n",
      "(rep layer 1) epoch: 0, loss: 49.869724\n",
      "(rep layer 1) epoch: 25, loss: 49.88531\n",
      "(rep layer 1) epoch: 50, loss: 49.87332\n",
      "(rep layer 1) epoch: 75, loss: 49.87692\n",
      "(rep layer 1) epoch: 100, loss: 49.869724\n",
      "(rep layer 1) epoch: 125, loss: 49.878117\n",
      "(rep layer 1) epoch: 150, loss: 49.872124\n",
      "(rep layer 1) epoch: 175, loss: 49.878117\n",
      "(rep layer 1) epoch: 200, loss: 49.87692\n",
      "(rep layer 1) epoch: 225, loss: 49.870922\n",
      "(rep layer 1) epoch: 250, loss: 49.879314\n",
      "(rep layer 1) epoch: 275, loss: 49.878117\n",
      "(rep layer 1) epoch: 300, loss: 49.87572\n",
      "(rep layer 1) epoch: 325, loss: 49.87692\n",
      "(rep layer 1) epoch: 350, loss: 49.87572\n",
      "(rep layer 1) epoch: 375, loss: 49.879314\n",
      "(rep layer 1) epoch: 400, loss: 49.880516\n",
      "(rep layer 1) epoch: 425, loss: 49.88291\n",
      "(rep layer 1) epoch: 450, loss: 49.872124\n",
      "(rep layer 1) epoch: 475, loss: 49.881714\n",
      "(rep layer 1) epoch: 500, loss: 49.87572\n",
      "(rep layer 1) epoch: 525, loss: 49.87452\n",
      "(rep layer 1) epoch: 550, loss: 49.87572\n",
      "(rep layer 1) epoch: 575, loss: 49.88291\n",
      "(rep layer 1) epoch: 600, loss: 49.891304\n",
      "(rep layer 1) epoch: 625, loss: 49.88411\n",
      "(rep layer 1) epoch: 650, loss: 49.868526\n",
      "(rep layer 1) epoch: 675, loss: 49.88291\n",
      "(rep layer 1) epoch: 700, loss: 49.878117\n",
      "(rep layer 1) epoch: 725, loss: 49.88531\n",
      "(rep layer 1) auc: 0.3731\n",
      "(rep layer 1) imtafe: 1.4\n",
      "final LCT  done and output saved, time taken: 518.92\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "print(\"finished obtaining representations, starting LCT\")\n",
    "# final LCT for each rep layer\n",
    "for i in range(vl_reps_1.shape[1]):\n",
    "    if i == 1:\n",
    "        t3 = time.time()\n",
    "        out_dat_f, out_lbs_f, losses_f = linear_classifier_test( linear_input_size, linear_batch_size, linear_n_epochs, \"adam\", linear_learning_rate, vl_reps_1[:,i,:], vl_lab_1, vl_reps_2[:,i,:], vl_lab_2 )\n",
    "        auc, imtafe = get_perf_stats( out_lbs_f, out_dat_f )\n",
    "        ep=0\n",
    "        step_size = 25\n",
    "        for lss in losses_f[::step_size]:\n",
    "            print( f\"(rep layer {i}) epoch: \" + str( ep ) + \", loss: \" + str( lss ), flush=True)\n",
    "            ep+=step_size\n",
    "        print( f\"(rep layer {i}) auc: \"+str( round(auc, 4) ), flush=True )\n",
    "        print( f\"(rep layer {i}) imtafe: \"+str( round(imtafe, 1) ), flush=True)\n",
    "        t4 = time.time()\n",
    "\n",
    "print( \"final LCT  done and output saved, time taken: \" + str( np.round( t4-t3, 2 ) ), flush=True )\n",
    "print(\"............................\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980a53c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:54:35.824100Z",
     "start_time": "2024-01-22T19:54:35.817284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_reps_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2105facc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:54:35.833818Z",
     "start_time": "2024-01-22T19:54:35.827454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_dat_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73b3917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:54:35.842355Z",
     "start_time": "2024-01-22T19:54:35.837156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_reps_1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8fccd9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T19:54:35.849928Z",
     "start_time": "2024-01-22T19:54:35.844684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embedding): Linear(in_features=3, out_features=1000, bias=True)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head_layers): ModuleList(\n",
      "    (0): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (1): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
