{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5be21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:13.275399Z",
     "start_time": "2024-02-06T23:17:10.803493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in /opt/conda/lib/python3.10/site-packages (0.61.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from memory_profiler) (5.9.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863be33e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:14.727543Z",
     "start_time": "2024-02-06T23:17:13.277644Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import argparse\n",
    "sys.path.append('../')\n",
    "\n",
    "# load torch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load custom modules required for jetCLR training\n",
    "from scripts.modules.jet_augs import rotate_jets, distort_jets, rescale_pts, crop_jets, translate_jets, collinear_fill_jets\n",
    "# from scripts.modules.transformer import Transformer\n",
    "from scripts.modules.losses import contrastive_loss, align_loss, uniform_loss\n",
    "from scripts.modules.perf_eval import get_perf_stats, linear_classifier_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c9bcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:14.734514Z",
     "start_time": "2024-02-06T23:17:14.729159Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(dataset_path, flag, n_files=-1):\n",
    "    if args.full_kinematics:\n",
    "        data_files = glob.glob(f\"{dataset_path}/{flag}/processed/7_features_raw/data/*\")\n",
    "    else:\n",
    "        data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features_raw/data/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        if args.full_kinematics:\n",
    "            data.append(np.load(f\"{dataset_path}/{flag}/processed/7_features_raw/data/data_{i}.npy\")) \n",
    "        else:\n",
    "            data.append(np.load(f\"{dataset_path}/{flag}/processed/3_features_raw/data/data_{i}.pt\")) \n",
    "        print(f\"--- loaded file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_labels(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/7_features_raw/labels/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data.append(np.load(f\"{dataset_path}/{flag}/processed/7_features_raw/labels/labels_{i}.npy\"))\n",
    "        print(f\"--- loaded label file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35304f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:14.854056Z",
     "start_time": "2024-02-06T23:17:14.736357Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971b285d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:14.895051Z",
     "start_time": "2024-02-06T23:17:14.855513Z"
    }
   },
   "outputs": [],
   "source": [
    "inpput_dim = 7\n",
    "args.sbratio = 1\n",
    "args.output_dim = 1000\n",
    "args.model_dim = 1000 \n",
    "args.n_heads = 4\n",
    "args.dim_feedforward= 1000\n",
    "args.n_layers= 4 \n",
    "args.learning_rate = 0.00005 \n",
    "args.n_head_layers = 2 \n",
    "args.opt = \"adam\"\n",
    "args.label = \"test-notebook\"\n",
    "# args.load_path = f\"/ssl-jet-vol-v2/JetCLR/models/experiments/{args.label}/model_ep20.pt\"\n",
    "args.trs = True\n",
    "args.mask = False\n",
    "args.cmask = True\n",
    "args.batch_size = 128\n",
    "args.trsw = 0.1\n",
    "args.full_kinematics = True\n",
    "args.num_files = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacb4bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:15.052052Z",
     "start_time": "2024-02-06T23:17:14.896240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "--- loaded file 0 from `train` directory\n",
      "--- loaded label file 0 from `train` directory\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print( \"loading data\")\n",
    "data = load_data(\"/ssl-jet-vol-v2/toptagging\", \"train\", args.num_files)\n",
    "labels = load_labels(\"/ssl-jet-vol-v2/toptagging\", \"train\", args.num_files)\n",
    "tr_dat_in = np.concatenate(data, axis=0)  # Concatenate along the first axis\n",
    "tr_lab_in = np.concatenate(labels, axis=0)\n",
    "tr_dat_in = tr_dat_in[:10]\n",
    "tr_lab_in = tr_lab_in[:10]\n",
    "print(tr_lab_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a56cc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:15.058984Z",
     "start_time": "2024-02-06T23:17:15.053455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  7\n",
      "shuffling data and doing the S/B split\n"
     ]
    }
   ],
   "source": [
    "# input dim to the transformer -> (pt,eta,phi)\n",
    "input_dim = tr_dat_in.shape[1]\n",
    "print(\"input_dim: \", input_dim)\n",
    "\n",
    "# creating the training dataset\n",
    "print( \"shuffling data and doing the S/B split\", flush=True )\n",
    "tr_bkg_dat = tr_dat_in[ tr_lab_in==0 ].copy()\n",
    "tr_sig_dat = tr_dat_in[ tr_lab_in==1 ].copy()\n",
    "nbkg_tr = int( tr_bkg_dat.shape[0] )\n",
    "nsig_tr = int( args.sbratio * nbkg_tr )\n",
    "list_tr_dat = list( tr_bkg_dat[ 0:nbkg_tr ] ) + list( tr_sig_dat[ 0:nsig_tr ] )\n",
    "list_tr_lab = [ 0 for i in range( nbkg_tr ) ] + [ 1 for i in range( nsig_tr ) ]\n",
    "ldz_tr = list( zip( list_tr_dat, list_tr_lab ) )\n",
    "random.shuffle( ldz_tr )\n",
    "tr_dat, tr_lab = zip( *ldz_tr )\n",
    "# reducing the training data\n",
    "tr_dat = np.array( tr_dat )\n",
    "tr_lab = np.array( tr_lab )\n",
    "\n",
    "# create two validation sets: \n",
    "# one for training the linear classifier test (LCT)\n",
    "# and one for testing on it\n",
    "# we will do this just with tr_dat_in, but shuffled and split 50/50\n",
    "# this should be fine because the jetCLR training doesn't use labels\n",
    "# we want the LCT to use S/B=1 all the time\n",
    "list_vl_dat = list( tr_dat_in.copy() )\n",
    "list_vl_lab = list( tr_lab_in.copy() )\n",
    "ldz_vl = list( zip( list_vl_dat, list_vl_lab ) )\n",
    "random.shuffle( ldz_vl )\n",
    "vl_dat, vl_lab = zip( *ldz_vl )\n",
    "vl_dat = np.array( vl_dat )\n",
    "vl_lab = np.array( vl_lab )\n",
    "vl_len = vl_dat.shape[0]\n",
    "vl_split_len = int( vl_len/2 )\n",
    "vl_dat_1 = vl_dat[ 0:vl_split_len ]\n",
    "vl_lab_1 = vl_lab[ 0:vl_split_len ]\n",
    "vl_dat_2 = vl_dat[ -vl_split_len: ]\n",
    "vl_lab_2 = vl_lab[ -vl_split_len: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aae1c5",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4b8323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:15.121133Z",
     "start_time": "2024-02-06T23:17:15.060085Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class for transformer network\n",
    "class Transformer(nn.Module):\n",
    "    # define and intialize the structure of the neural network\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        model_dim,\n",
    "        output_dim,\n",
    "        n_heads,\n",
    "        dim_feedforward,\n",
    "        n_layers,\n",
    "        learning_rate,\n",
    "        n_head_layers=2,\n",
    "        head_norm=False,\n",
    "        dropout=0.1,\n",
    "        opt=\"adam\",\n",
    "        log=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # define hyperparameters\n",
    "        self.input_dim = input_dim\n",
    "        self.model_dim = model_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.n_layers = n_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_head_layers = n_head_layers\n",
    "        self.head_norm = head_norm\n",
    "        self.dropout = dropout\n",
    "        self.log = log\n",
    "        # define subnetworks\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                model_dim, n_heads, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "            ),\n",
    "            n_layers,\n",
    "        )\n",
    "        # head_layers have output_dim\n",
    "        if n_head_layers == 0:\n",
    "            self.head_layers = []\n",
    "        else:\n",
    "            if head_norm:\n",
    "                self.norm_layers = nn.ModuleList([nn.LayerNorm(model_dim)])\n",
    "            self.head_layers = nn.ModuleList([nn.Linear(model_dim, output_dim)])\n",
    "            for i in range(n_head_layers - 1):\n",
    "                if head_norm:\n",
    "                    self.norm_layers.append(nn.LayerNorm(output_dim))\n",
    "                self.head_layers.append(nn.Linear(output_dim, output_dim))\n",
    "        # option to use adam or sgd\n",
    "        if opt == \"adam\":\n",
    "            self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        if opt == \"sgdca\" or opt == \"sgdslr\" or opt == \"sgd\":\n",
    "            self.optimizer = torch.optim.SGD(\n",
    "                self.parameters(), lr=self.learning_rate, momentum=0.9\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        inpt,\n",
    "        mask=None,\n",
    "        use_mask=False,\n",
    "        use_continuous_mask=False,\n",
    "        mult_reps=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input here is (batch_size, n_constit, 3 or 7)\n",
    "        but transformer expects (n_constit, batch_size, 3 or 7) so we need to transpose\n",
    "        if use_mask is True, will mask out all inputs with pT=0\n",
    "        \"\"\"\n",
    "        print(f\"input shape: {inpt.shape}\")\n",
    "        assert not (use_mask and use_continuous_mask)\n",
    "        pt_index = 2 if args.full_kinematics else 0\n",
    "        # make a copy\n",
    "        x = inpt + 0.0\n",
    "        if use_mask:\n",
    "            pT_zero = x[:, :, pt_index] == 0\n",
    "        if use_continuous_mask:\n",
    "            if self.log:\n",
    "                log_pT = x[:, :, pt_index]\n",
    "                # exponentiate to get actual pT\n",
    "                pT = torch.where(log_pT != 0, torch.exp(log_pT), torch.zeros_like(log_pT))\n",
    "            else:\n",
    "                pT = x[:, :, pt_index]\n",
    "            print(f\"pT: {pT}\")\n",
    "        if use_mask:\n",
    "            mask = self.make_mask(pT_zero).to(x.device)\n",
    "        elif use_continuous_mask:\n",
    "            mask = self.make_continuous_mask(pT).to(x.device)\n",
    "        else:\n",
    "            mask = None\n",
    "        print(f\"mask : {mask}\")\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        # (n_constit, batch_size, model_dim)\n",
    "        x = self.embedding(x)\n",
    "        print(f\"after embedding: {x.shape}\")\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        print(f\"after transformer: {x.shape}\")\n",
    "        if use_mask:\n",
    "            # set masked constituents to zero\n",
    "            # otherwise the sum will change if the constituents with 0 pT change\n",
    "            x[torch.transpose(pT_zero, 0, 1)] = 0\n",
    "        elif use_continuous_mask:\n",
    "            # scale x by pT, so that function is IR safe\n",
    "            # transpose first to get correct shape\n",
    "#             x *= torch.transpose(pT, 0, 1)[:, :, None]\n",
    "            pass\n",
    "        # sum over sequence dim\n",
    "        # (batch_size, model_dim)\n",
    "        x = x.sum(0)\n",
    "        print(f\"after summing: {x.shape}\")\n",
    "        return self.head(x, mult_reps)\n",
    "\n",
    "    def head(self, x, mult_reps):\n",
    "        \"\"\"\n",
    "        calculates output of the head if it exists, i.e. if n_head_layer>0\n",
    "        returns multiple representation layers if asked for by mult_reps = True\n",
    "        input:  x shape=(batchsize, model_dim)\n",
    "                mult_reps boolean\n",
    "        output: reps shape=(batchsize, output_dim)                  for mult_reps=False\n",
    "                reps shape=(batchsize, number_of_reps, output_dim)  for mult_reps=True\n",
    "        \"\"\"\n",
    "        relu = nn.ReLU()\n",
    "        if mult_reps == True:\n",
    "            if self.n_head_layers > 0:\n",
    "                reps = torch.empty(x.shape[0], self.n_head_layers + 1, self.output_dim)\n",
    "                # Transform x to output_dim size before assignment\n",
    "                x_transformed = (\n",
    "                    self.head_layers[0](relu(x)) if self.n_head_layers > 0 else x\n",
    "                )\n",
    "                reps[:, 0] = x_transformed\n",
    "                for i, layer in enumerate(self.head_layers):\n",
    "                    if self.head_norm:\n",
    "                        x = self.norm_layers[i](x)\n",
    "                    x = relu(x)\n",
    "                    x = layer(x)\n",
    "                    reps[:, i + 1] = x\n",
    "                return reps\n",
    "            else:\n",
    "                reps = x[:, None, :]\n",
    "                return reps\n",
    "        else:\n",
    "            for i, layer in enumerate(self.head_layers):\n",
    "                if self.head_norm:\n",
    "                    x = self.norm_layers[i](x)\n",
    "                x = relu(x)\n",
    "                x = layer(x)\n",
    "            return x\n",
    "\n",
    "    def forward_batchwise(\n",
    "        self, x, batch_size, use_mask=False, use_continuous_mask=False\n",
    "    ):\n",
    "        device = next(self.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            if self.n_head_layers == 0:\n",
    "                rep_dim = self.model_dim\n",
    "                number_of_reps = 1\n",
    "            elif self.n_head_layers > 0:\n",
    "                rep_dim = self.output_dim\n",
    "                number_of_reps = self.n_head_layers + 1\n",
    "            out = torch.empty(x.size(0), number_of_reps, rep_dim)\n",
    "            idx_list = torch.split(torch.arange(x.size(0)), batch_size)\n",
    "            for idx in idx_list:\n",
    "                output = (\n",
    "                    self(\n",
    "                        x[idx].to(device),\n",
    "                        use_mask=use_mask,\n",
    "                        use_continuous_mask=use_continuous_mask,\n",
    "                        mult_reps=True,\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                )\n",
    "                out[idx] = output\n",
    "        return out\n",
    "\n",
    "    def make_mask(self, pT_zero):\n",
    "        \"\"\"\n",
    "        Input: batch of bools of whether pT=0, shape (batchsize, n_constit)\n",
    "        Output: mask for transformer model which masks out constituents with pT=0, shape (batchsize*n_transformer_heads, n_constit, n_constit)\n",
    "        mask is added to attention output before softmax: 0 means value is unchanged, -inf means it will be masked\n",
    "        \"\"\"\n",
    "        n_constit = pT_zero.size(1)\n",
    "        pT_zero = torch.repeat_interleave(pT_zero, self.n_heads, axis=0)\n",
    "        pT_zero = torch.repeat_interleave(pT_zero[:, None], n_constit, axis=1)\n",
    "        mask = torch.zeros(pT_zero.size(0), n_constit, n_constit)\n",
    "        mask[pT_zero] = -np.inf\n",
    "#         print(f\"mask: {mask}\")\n",
    "        return mask\n",
    "\n",
    "    def make_continuous_mask(self, pT):\n",
    "        \"\"\"\n",
    "        Input: batch of pT values, shape (batchsize, n_constit)\n",
    "        Output: mask for transformer model: -1/pT, shape (batchsize*n_transformer_heads, n_constit, n_constit)\n",
    "        mask is added to attention output before softmax: 0 means value is unchanged, -inf means it will be masked\n",
    "        intermediate values mean it is partly masked\n",
    "        This function implements IR safety in the transformer\n",
    "        \"\"\"\n",
    "#         print(f\"pT : {pT}\")\n",
    "        n_constit = pT.size(1)\n",
    "        pT_reshape = torch.repeat_interleave(pT, self.n_heads, axis=0)\n",
    "        pT_reshape = torch.repeat_interleave(pT_reshape[:, None], n_constit, axis=1)\n",
    "        # mask = -1/pT_reshape\n",
    "        mask = 0.5 * torch.log(pT_reshape)\n",
    "#         print(f\"mask: {mask}\")\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39398fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.090135Z",
     "start_time": "2024-02-06T23:17:15.122307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising the network\n",
      "peak memory: 1013.61 MiB, increment: 104.00 MiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Linear(in_features=7, out_features=1000, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head_layers): ModuleList(\n",
       "    (0): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set-up parameters for the LCT\n",
    "linear_input_size = args.output_dim\n",
    "linear_n_epochs = 750\n",
    "linear_learning_rate = 0.001\n",
    "linear_batch_size = 128\n",
    "\n",
    "# initialise the network\n",
    "print( \"initialising the network\", flush=True )\n",
    "%memit net = Transformer( input_dim, args.model_dim, args.output_dim, args.n_heads, args.dim_feedforward, args.n_layers, args.learning_rate, args.n_head_layers, dropout=0.1, opt=args.opt, log=args.full_kinematics )\n",
    "# send network to device\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "net.to( device )\n",
    "# print(net)\n",
    "# net.load_state_dict(torch.load(f\"{args.load_path}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabdbf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.850935Z",
     "start_time": "2024-02-06T23:17:17.092755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the final LCT run\n",
      "obtaining representations\n",
      "input shape: torch.Size([5, 50, 7])\n",
      "pT: tensor([[1.4794e+02, 5.5542e+01, 4.3797e+01, 3.4844e+01, 2.9229e+01, 2.6833e+01,\n",
      "         2.2414e+01, 2.1758e+01, 1.7662e+01, 1.5363e+01, 1.4716e+01, 1.3230e+01,\n",
      "         1.2635e+01, 8.8253e+00, 8.7712e+00, 8.7003e+00, 7.9881e+00, 7.3455e+00,\n",
      "         6.1866e+00, 5.4705e+00, 5.0854e+00, 4.7240e+00, 3.6427e+00, 3.5194e+00,\n",
      "         3.1081e+00, 3.1059e+00, 3.0073e+00, 2.9894e+00, 2.1623e+00, 2.1467e+00,\n",
      "         2.0780e+00, 1.5348e+00, 1.4796e+00, 1.1885e+00, 1.1550e+00, 9.1264e-01,\n",
      "         7.1755e-01, 6.6400e-01, 5.3050e-01, 4.5812e-01, 3.7212e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [7.8762e+01, 7.4373e+01, 5.7039e+01, 5.4135e+01, 4.6028e+01, 3.6450e+01,\n",
      "         2.1482e+01, 1.9150e+01, 1.8814e+01, 1.4018e+01, 1.2491e+01, 1.2001e+01,\n",
      "         1.0184e+01, 9.9931e+00, 8.4996e+00, 7.6117e+00, 7.1444e+00, 6.5805e+00,\n",
      "         6.2218e+00, 5.9061e+00, 5.6266e+00, 5.0699e+00, 3.7438e+00, 3.7046e+00,\n",
      "         3.6252e+00, 3.3900e+00, 2.3005e+00, 2.0764e+00, 2.0549e+00, 2.0322e+00,\n",
      "         1.9476e+00, 1.9362e+00, 1.9314e+00, 1.7719e+00, 1.7676e+00, 1.7167e+00,\n",
      "         1.7028e+00, 1.5161e+00, 1.2340e+00, 1.1811e+00, 1.0948e+00, 1.0735e+00,\n",
      "         1.0566e+00, 9.6297e-01, 9.0848e-01, 7.6128e-01, 7.1470e-01, 7.0961e-01,\n",
      "         6.2414e-01, 6.0037e-01],\n",
      "        [1.6335e+02, 7.4949e+01, 6.8273e+01, 5.9983e+01, 5.3907e+01, 5.0164e+01,\n",
      "         4.2075e+01, 3.5531e+01, 1.2396e+01, 1.1754e+01, 1.0270e+01, 7.5426e+00,\n",
      "         6.8523e+00, 3.5274e+00, 3.0418e+00, 1.9196e+00, 1.8388e+00, 1.5274e+00,\n",
      "         1.3473e+00, 1.2945e+00, 1.1249e+00, 7.5386e-01, 7.0623e-01, 4.8962e-01,\n",
      "         1.6176e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.3570e+02, 7.4921e+01, 7.4617e+01, 2.8703e+01, 1.5739e+01, 1.4527e+01,\n",
      "         1.3639e+01, 9.7145e+00, 8.0963e+00, 7.3065e+00, 6.7765e+00, 6.2793e+00,\n",
      "         4.6660e+00, 4.0159e+00, 2.7388e+00, 2.0411e+00, 1.8675e+00, 1.7227e+00,\n",
      "         1.6279e+00, 1.2760e+00, 1.1427e+00, 5.0933e-01, 3.1603e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [9.1794e+01, 4.4225e+01, 3.6026e+01, 3.1902e+01, 2.7652e+01, 2.4420e+01,\n",
      "         1.9129e+01, 1.7828e+01, 1.3733e+01, 1.3697e+01, 1.2559e+01, 1.1851e+01,\n",
      "         1.1602e+01, 1.0475e+01, 9.5934e+00, 8.9466e+00, 7.8936e+00, 7.4530e+00,\n",
      "         7.3123e+00, 6.5921e+00, 6.2608e+00, 6.2206e+00, 6.0871e+00, 5.9607e+00,\n",
      "         5.9135e+00, 5.6999e+00, 5.4269e+00, 5.3992e+00, 5.3000e+00, 5.1529e+00,\n",
      "         4.5574e+00, 4.4680e+00, 4.3851e+00, 4.2806e+00, 4.2572e+00, 4.1552e+00,\n",
      "         4.1523e+00, 4.1144e+00, 3.9633e+00, 3.4226e+00, 3.3403e+00, 3.1056e+00,\n",
      "         2.6767e+00, 2.4798e+00, 2.1242e+00, 2.1065e+00, 2.1015e+00, 2.0663e+00,\n",
      "         1.9861e+00, 1.9374e+00]], device='cuda:0')\n",
      "mask : tensor([[[2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         ...,\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         ...,\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         ...,\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf],\n",
      "         [2.4984, 2.0086, 1.8898,  ...,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         ...,\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307]],\n",
      "\n",
      "        [[2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         ...,\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307]],\n",
      "\n",
      "        [[2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         ...,\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307],\n",
      "         [2.2598, 1.8946, 1.7921,  ..., 0.3629, 0.3431, 0.3307]]],\n",
      "       device='cuda:0')\n",
      "after embedding: torch.Size([50, 5, 1000])\n",
      "after transformer: torch.Size([50, 5, 1000])\n",
      "after summing: torch.Size([5, 1000])\n",
      "finished obtaining representations, starting LCT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print( \"starting the final LCT run\", flush=True )\n",
    "print(\"obtaining representations\")\n",
    "# evaluate the network on the testing data, applying some augmentations first if it's required\n",
    "# if args.trs:\n",
    "#     vl_dat_1 = translate_jets( vl_dat_1, width=args.trsw )\n",
    "#     vl_dat_2 = translate_jets( vl_dat_2, width=args.trsw )\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    #vl_reps_1 = F.normalize( net.forward_batchwise( torch.Tensor( vl_dat_1 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu(), dim=-1 ).numpy()\n",
    "    #vl_reps_2 = F.normalize( net.forward_batchwise( torch.Tensor( vl_dat_2 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu(), dim=-1 ).numpy()\n",
    "    vl_reps_1 = net.forward_batchwise( torch.Tensor( vl_dat_1 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu().numpy()\n",
    "#     vl_reps_2 = net.forward_batchwise( torch.Tensor( vl_dat_2 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu().numpy()\n",
    "    net.train()\n",
    "#     del vl_dat_1, vl_dat_2\n",
    "#     del net\n",
    "#     gc.collect()\n",
    "print(\"finished obtaining representations, starting LCT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67a2cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.856434Z",
     "start_time": "2024-02-06T23:17:17.852358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-13.654608  ,  23.118135  , -17.19412   , ...,  35.22066   ,\n",
       "          20.608694  , -44.329098  ],\n",
       "        [-13.654608  ,  23.118135  , -17.19412   , ...,  35.22066   ,\n",
       "          20.608694  , -44.329098  ],\n",
       "        [  4.5870886 ,   1.2627772 ,  -4.2939386 , ...,   3.5898564 ,\n",
       "          -2.4007485 , -15.663402  ]],\n",
       "\n",
       "       [[  2.9299662 ,  19.328493  , -11.448227  , ...,  22.024143  ,\n",
       "          12.216901  , -61.507187  ],\n",
       "        [  2.9299662 ,  19.328493  , -11.448227  , ...,  22.024143  ,\n",
       "          12.216901  , -61.507187  ],\n",
       "        [ -3.06046   ,  -3.3615606 ,  -7.2038755 , ...,   2.6103375 ,\n",
       "          -5.6897707 , -17.941868  ]],\n",
       "\n",
       "       [[  1.8149749 ,   8.06336   , -13.503469  , ...,  26.003977  ,\n",
       "           2.6337273 , -50.747673  ],\n",
       "        [  1.8149749 ,   8.06336   , -13.503469  , ...,  26.003977  ,\n",
       "           2.6337273 , -50.747673  ],\n",
       "        [  1.25453   ,  -1.1534108 ,  -4.2633305 , ...,   3.3173125 ,\n",
       "          -3.9180858 , -16.847599  ]],\n",
       "\n",
       "       [[ -6.336482  ,  16.81661   , -21.754772  , ...,  30.005371  ,\n",
       "          13.783426  , -48.299664  ],\n",
       "        [ -6.336482  ,  16.81661   , -21.754772  , ...,  30.005371  ,\n",
       "          13.783426  , -48.299664  ],\n",
       "        [  2.19823   ,   1.3154889 ,  -3.3613224 , ...,   6.163824  ,\n",
       "          -2.1552505 , -13.290805  ]],\n",
       "\n",
       "       [[-18.652596  ,  22.707373  ,   5.803379  , ...,  33.409073  ,\n",
       "          12.889077  , -50.685345  ],\n",
       "        [-18.652596  ,  22.707373  ,   5.803379  , ...,  33.409073  ,\n",
       "          12.889077  , -50.685345  ],\n",
       "        [  1.2424722 ,  -6.125164  ,  -4.6433682 , ...,  -0.27070218,\n",
       "          -2.257375  , -18.37995   ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_reps_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a96a702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.948105Z",
     "start_time": "2024-02-06T23:17:17.857682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the final LCT run\n",
      "obtaining representations\n",
      "input shape: torch.Size([5, 50, 7])\n",
      "mask : tensor([[[0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "         [0., 0., 0.,  ..., -inf, -inf, -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n",
      "after embedding: torch.Size([50, 5, 1000])\n",
      "after transformer: torch.Size([50, 5, 1000])\n",
      "after summing: torch.Size([5, 1000])\n",
      "finished obtaining representations, starting LCT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print( \"starting the final LCT run\", flush=True )\n",
    "print(\"obtaining representations\")\n",
    "# evaluate the network on the testing data, applying some augmentations first if it's required\n",
    "# if args.trs:\n",
    "#     vl_dat_1 = translate_jets( vl_dat_1, width=args.trsw )\n",
    "#     vl_dat_2 = translate_jets( vl_dat_2, width=args.trsw )\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    args.mask = True\n",
    "    args.cmask = False\n",
    "    #vl_reps_1 = F.normalize( net.forward_batchwise( torch.Tensor( vl_dat_1 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu(), dim=-1 ).numpy()\n",
    "    #vl_reps_2 = F.normalize( net.forward_batchwise( torch.Tensor( vl_dat_2 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu(), dim=-1 ).numpy()\n",
    "    vl_reps_1 = net.forward_batchwise( torch.Tensor( vl_dat_1 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu().numpy()\n",
    "#     vl_reps_2 = net.forward_batchwise( torch.Tensor( vl_dat_2 ).transpose(1,2), args.batch_size, use_mask=args.mask, use_continuous_mask=args.cmask ).detach().cpu().numpy()\n",
    "    net.train()\n",
    "#     del vl_dat_1, vl_dat_2\n",
    "#     del net\n",
    "#     gc.collect()\n",
    "print(\"finished obtaining representations, starting LCT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "088459e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.953355Z",
     "start_time": "2024-02-06T23:17:17.949789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-10.8137245 ,  20.04731   , -12.585735  , ...,  30.353998  ,\n",
       "          21.448772  , -43.442318  ],\n",
       "        [-10.8137245 ,  20.04731   , -12.585735  , ...,  30.353998  ,\n",
       "          21.448772  , -43.442318  ],\n",
       "        [  2.7370608 ,   2.056719  ,  -3.056351  , ...,   1.1202877 ,\n",
       "          -2.482028  , -13.235533  ]],\n",
       "\n",
       "       [[  1.5579587 ,  19.09314   , -11.285239  , ...,  23.047926  ,\n",
       "          18.242231  , -67.74737   ],\n",
       "        [  1.5579587 ,  19.09314   , -11.285239  , ...,  23.047926  ,\n",
       "          18.242231  , -67.74737   ],\n",
       "        [ -2.3121598 ,  -0.52468693,  -6.8692713 , ...,   1.7296107 ,\n",
       "          -7.405306  , -16.74133   ]],\n",
       "\n",
       "       [[  2.3459933 ,   9.238085  ,  -5.801456  , ...,  11.23956   ,\n",
       "           7.154127  , -31.271805  ],\n",
       "        [  2.3459933 ,   9.238085  ,  -5.801456  , ...,  11.23956   ,\n",
       "           7.154127  , -31.271805  ],\n",
       "        [ -1.2445474 ,  -0.57823384,  -3.5734456 , ...,   1.0001347 ,\n",
       "          -4.175991  ,  -8.271915  ]],\n",
       "\n",
       "       [[ -2.3444216 ,  10.851338  ,  -8.238062  , ...,  12.756558  ,\n",
       "          11.515416  , -27.308235  ],\n",
       "        [ -2.3444216 ,  10.851338  ,  -8.238062  , ...,  12.756558  ,\n",
       "          11.515416  , -27.308235  ],\n",
       "        [ -0.31738433,   0.93207544,  -3.2558968 , ...,   1.8967168 ,\n",
       "          -2.72888   ,  -6.370695  ]],\n",
       "\n",
       "       [[-17.070452  ,  22.846018  ,   6.6119156 , ...,  33.553375  ,\n",
       "          16.243267  , -53.33658   ],\n",
       "        [-17.070452  ,  22.846018  ,   6.6119156 , ...,  33.553375  ,\n",
       "          16.243267  , -53.33658   ],\n",
       "        [  1.158988  ,  -4.675334  ,  -4.7337046 , ...,  -1.336869  ,\n",
       "          -2.3757565 , -18.583414  ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_reps_1[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ffbac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.956105Z",
     "start_time": "2024-02-06T23:17:17.954485Z"
    }
   },
   "outputs": [],
   "source": [
    "# del tr_dat_in, tr_bkg_dat, tr_sig_dat, tr_dat, vl_dat\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67870df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T23:17:17.959139Z",
     "start_time": "2024-02-06T23:17:17.957240Z"
    }
   },
   "outputs": [],
   "source": [
    "# # final LCT for each rep layer\n",
    "# for run in range(3):\n",
    "#     for i in range(vl_reps_1.shape[1]):\n",
    "#         if i == 1:\n",
    "#             out_dat_f, out_lbs_f, losses_f, val_losses_f = linear_classifier_test( linear_input_size, linear_batch_size, linear_n_epochs, \"adam\", linear_learning_rate, vl_reps_1[:,i,:], np.expand_dims(vl_lab_1, axis=1), vl_reps_2[:,i,:], np.expand_dims(vl_lab_2, axis=1) )\n",
    "#             auc, imtafe = get_perf_stats( out_lbs_f, out_dat_f )\n",
    "#             ep=0\n",
    "#             step_size = 25\n",
    "#             for (lss, val_lss) in zip(losses_f[::step_size], val_losses_f):\n",
    "#                 print( f\"(rep layer {i}) epoch: \" + str( ep ) + \", loss: \" + str( lss ) + \", val loss: \" + str( val_lss ), flush=True)\n",
    "#                 ep+=step_size\n",
    "#             print( f\"(rep layer {i}) auc: \"+str( round(auc, 4) ), flush=True )\n",
    "#             print( f\"(rep layer {i}) imtafe: \"+str( round(imtafe, 1) ), flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
