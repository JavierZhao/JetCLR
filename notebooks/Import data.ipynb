{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ecd3b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:39.691772Z",
     "start_time": "2024-02-12T20:01:38.403925Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef035e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:40.517500Z",
     "start_time": "2024-02-12T20:01:39.694816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssl-jet-vol-v2/JetCLR/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7b8815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:40.524460Z",
     "start_time": "2024-02-12T20:01:40.520107Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.load_labels = True\n",
    "args.raw = 1\n",
    "args.percent = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f548ffd",
   "metadata": {},
   "source": [
    "## Import data using JetClassDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246ec146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:07:52.691641Z",
     "start_time": "2024-02-12T20:07:52.684615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data files: 50\n",
      "Data files: ['data_0.pt', 'data_1.pt', 'data_10.pt', 'data_11.pt', 'data_12.pt', 'data_13.pt', 'data_14.pt', 'data_15.pt', 'data_16.pt', 'data_17.pt', 'data_18.pt', 'data_19.pt', 'data_2.pt', 'data_20.pt', 'data_21.pt', 'data_22.pt', 'data_23.pt', 'data_24.pt', 'data_25.pt', 'data_26.pt', 'data_27.pt', 'data_28.pt', 'data_29.pt', 'data_3.pt', 'data_30.pt', 'data_31.pt', 'data_32.pt', 'data_33.pt', 'data_34.pt', 'data_35.pt', 'data_36.pt', 'data_37.pt', 'data_38.pt', 'data_39.pt', 'data_4.pt', 'data_40.pt', 'data_41.pt', 'data_42.pt', 'data_43.pt', 'data_44.pt', 'data_45.pt', 'data_46.pt', 'data_47.pt', 'data_48.pt', 'data_49.pt', 'data_5.pt', 'data_6.pt', 'data_7.pt', 'data_8.pt', 'data_9.pt']\n",
      "jets per file: 100000\n",
      "total jets: 5000000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from modules.dataset.dataset import JetClassDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize your custom dataset\n",
    "dataset_path = '/ssl-jet-vol-v2/JetClass/processed/raw'\n",
    "train_dataset = JetClassDataset(\n",
    "        dataset_path,\n",
    "        flag=\"train\",\n",
    "        args=args,\n",
    "        logfile=sys.stdout,\n",
    "        load_labels=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb6f67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:11:27.623274Z",
     "start_time": "2024-02-12T20:11:20.732742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▏                                                    | 1562/39063 [00:06<02:33, 244.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m batch_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     print(batch_counter)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     batch_counter += 1\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Now `data` contains your batch of jets, and `labels` contains the corresponding labels\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     print(data.shape)  # This will show the shape of your batch of jets\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     print(labels.shape)  # This will show the shape of your batch of labels\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1272\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1272\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1274\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "batch_counter = 0\n",
    "for data in tqdm(data_loader):\n",
    "    pass\n",
    "#     print(batch_counter)\n",
    "#     batch_counter += 1\n",
    "    # Now `data` contains your batch of jets, and `labels` contains the corresponding labels\n",
    "#     print(data.shape)  # This will show the shape of your batch of jets\n",
    "#     print(labels.shape)  # This will show the shape of your batch of labels\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7e403c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:08:24.848130Z",
     "start_time": "2024-02-12T20:08:24.845270Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = train_dataset.get_sample_shape()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b540fb04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:10:54.301195Z",
     "start_time": "2024-02-12T20:10:54.297494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dfb717",
   "metadata": {},
   "source": [
    "## Import data using simclr functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824f033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.652053Z",
     "start_time": "2024-02-12T20:01:55.652041Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(dataset_path, flag, n_files=-1):\n",
    "    if args.raw:\n",
    "        data_files = glob.glob(f\"{dataset_path}/raw/raw_{flag}_{args.percent}%/data/*\")\n",
    "    else:\n",
    "        data_files = glob.glob(f\"{dataset_path}/{flag}_{args.percent}%/data/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data.append(torch.load(file)) \n",
    "        print(f\"--- loaded file {file} from `{flag}_{args.percent}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_labels(dataset_path, flag, n_files=-1):\n",
    "    if args.raw:\n",
    "        data_files = glob.glob(f\"{dataset_path}/raw/raw_{flag}_{args.percent}%/label/*\")\n",
    "    else:\n",
    "        data_files = glob.glob(f\"{dataset_path}/{flag}_{args.percent}%/label/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data.append(torch.load(file)) \n",
    "        print(f\"--- loaded file {file} from `{flag}_{args.percent}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea3be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.653169Z",
     "start_time": "2024-02-12T20:01:55.653158Z"
    }
   },
   "outputs": [],
   "source": [
    "args.percent = 5\n",
    "print( \"loading data\")\n",
    "data = load_data(\"/ssl-jet-vol-v2/JetClass/processed\", \"val\")\n",
    "labels = load_labels(\"/ssl-jet-vol-v2/JetClass/processed\", \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f0550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.654207Z",
     "start_time": "2024-02-12T20:01:55.654197Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in data:\n",
    "    print(file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d95879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.655264Z",
     "start_time": "2024-02-12T20:01:55.655254Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in labels:\n",
    "    print(file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164ef52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.656196Z",
     "start_time": "2024-02-12T20:01:55.656186Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(data[2][:50000], \"data_0.pt\")\n",
    "torch.save(data[2][50000:], \"data_1.pt\")\n",
    "torch.save(data[0][:50000], \"data_2.pt\")\n",
    "torch.save(data[0][50000:], \"data_3.pt\")\n",
    "torch.save(data[1], \"data_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf094f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.657308Z",
     "start_time": "2024-02-12T20:01:55.657298Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(labels[1][:50000], \"labels_0.pt\")\n",
    "torch.save(labels[1][50000:], \"labels_0_1.pt\")\n",
    "torch.save(labels[2][:50000], \"labels_0_2.pt\")\n",
    "torch.save(labels[2][50000:], \"labels_0_3.pt\")\n",
    "torch.save(labels[0], \"labels_0_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12da6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef50f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.658324Z",
     "start_time": "2024-02-12T20:01:55.658313Z"
    }
   },
   "outputs": [],
   "source": [
    "hbb_raw = torch.load(\"/ssl-jet-vol-v2/JetClass/processed/raw/val/data/HToBB_120.pt\")\n",
    "hbb = torch.load(\"/ssl-jet-vol-v2/JetClass/processed/val/data/HToBB_120.pt\")\n",
    "labels_hbb_raw = torch.load(\"/ssl-jet-vol-v2/JetClass/processed/raw/val/label/labels_HToBB_120.pt\")\n",
    "hbb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3379ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.659343Z",
     "start_time": "2024-02-12T20:01:55.659332Z"
    }
   },
   "outputs": [],
   "source": [
    "hbb_raw.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35412319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.660347Z",
     "start_time": "2024-02-12T20:01:55.660337Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_hbb_raw.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ef41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.661361Z",
     "start_time": "2024-02-12T20:01:55.661350Z"
    }
   },
   "outputs": [],
   "source": [
    "hbb_raw[:10, 2:, :20] - hbb[:10, 2:, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0cc78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.662364Z",
     "start_time": "2024-02-12T20:01:55.662354Z"
    }
   },
   "outputs": [],
   "source": [
    "hbb[:10, 0, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcff38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.663386Z",
     "start_time": "2024-02-12T20:01:55.663376Z"
    }
   },
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4b8a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T20:01:55.664373Z",
     "start_time": "2024-02-12T20:01:55.664363Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_dat_in = torch.stack(data, axis=0)  # Concatenate along the first axis\n",
    "tr_lab_in = torch.stack(labels, axis=0)\n",
    "\n",
    "# input dim to the transformer -> (pt,eta,phi)\n",
    "input_dim = tr_dat_in.shape\n",
    "print(input_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
